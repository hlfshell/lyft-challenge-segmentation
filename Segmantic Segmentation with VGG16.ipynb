{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmantic Segmentation with VGG16\n",
    "\n",
    "The initial attempt with using a GAN hit a wall, specifically with figuring out how to do proper layer sizing for the transposed convolution layers for the generator. On top of that, some research I did during my \"off\" time showed that the approach semantic segmentation using either an FCN (Fully Convolutional Network) approach or SegNet would work best.\n",
    "\n",
    "Since SegNet is completely new, whereas transfer learning with VGG16 is something I'm familiar with, I'm going to attempt a VGG16 network here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n",
      "TensorFlow Version: 1.6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from glob import glob\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "#Check GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful variables\n",
    "num_classes = 13 # none and 12 options, 0-12\n",
    "image_shape = (160, 576)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load VGG16\n",
    "\n",
    "\n",
    "First we're going to load VGG16 with pretrained weights (so it maintains its feature detectors, which can be useful for our smaller dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "#Download VGG16 if it is not already\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "\n",
    "if not os.path.exists(\"vgg16.zip\"):\n",
    "    urlretrieve(\n",
    "        'https://s3-us-west-1.amazonaws.com/udacity-selfdrivingcar/vgg.zip',\n",
    "        \"./vgg16.zip\")\n",
    "    print(\"Downloaded VGG16 model weights\")\n",
    "else:\n",
    "    print(\"Already exists, skipping download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists, skipping extraction\n"
     ]
    }
   ],
   "source": [
    "#Extract if needed\n",
    "if not os.path.exists(\"./vgg\"):\n",
    "    unzip = zipfile.ZipFile(\"./vgg16.zip\", \"r\")\n",
    "    unzip.extractall(\"./\")\n",
    "    unzip.close()\n",
    "    print(\"Extracted VGG16 model weights\")\n",
    "else:\n",
    "    print(\"Already exists, skipping extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a map more colorful\n",
    "def convertToColor(value):\n",
    "    colors = [\n",
    "        (255, 255, 255),   #0\n",
    "        (255, 0, 0),      #1\n",
    "        (0, 255, 0),      #2\n",
    "        (0, 0, 255),      #3\n",
    "        (255, 255, 0),    #4\n",
    "        (127, 0, 255),    #5\n",
    "        (51, 255, 51),    #6\n",
    "        (255, 0, 127),    #7\n",
    "        (127, 127, 127),  #8\n",
    "        (0, 0, 0),        #9\n",
    "        (0, 255, 255),  #10\n",
    "        (0, 0, 100),      #11\n",
    "        (100, 0, 0),      #12\n",
    "    ]\n",
    "    return colors[value[0]]\n",
    "\n",
    "def colorizeMap(img):\n",
    "    return [list( map(convertToColor, row) ) for row in img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to be able to convert the image map to a 13 channel ground truth map, and vice versa\n",
    "def pixelToTruth(value):\n",
    "    truths = [\n",
    "        (1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "        (0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "        (0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "        (0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "        (0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0),\n",
    "        (0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0),\n",
    "        (0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0),\n",
    "        (0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0),\n",
    "        (0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0),\n",
    "        (0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0),\n",
    "        (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0),\n",
    "        (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0),\n",
    "        (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1)\n",
    "    ]\n",
    "    \n",
    "    return truths[value[0]]\n",
    "\n",
    "def truthToPixel(value):\n",
    "    return (value.tolist().index(1), 0, 0)\n",
    "\n",
    "def imageToTruth(img):\n",
    "    return [list(map(pixelToTruth, row)) for row in img]\n",
    "\n",
    "def truthToImage(truth):\n",
    "    return [list(map(truthToPixel, row)) for row in truth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the image data and the label for it\n",
    "def get_training_data(batch_size):\n",
    "    #Both inputs and ground truth maps have the same name - easy!\n",
    "    image_paths = glob(os.path.join(\"./data/Train/CameraRGB\", \"*.png\"))\n",
    "    label_paths = glob(os.path.join(\"./data/Train/CameraSeg\", \"*.png\"))\n",
    "    \n",
    "    for batch in range(0, len(image_paths), batch_size):\n",
    "        images = []\n",
    "        maps = []\n",
    "        \n",
    "        for index, image_file in enumerate(image_paths[batch:batch + batch_size]):\n",
    "#             map_file = os.path.join(\"./data/Train/CameraSeg\", label_paths[os.path.basename(image_file)])\n",
    "            map_file = os.path.join(label_paths[index])\n",
    "            \n",
    "            image = cv2.imread(image_file)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, image_shape)\n",
    "            map_image = cv2.imread(map_file)\n",
    "            map_image = cv2.cvtColor(map_image, cv2.COLOR_BGR2RGB)\n",
    "            map_image = cv2.resize(map_image, image_shape)\n",
    "            map_image = imageToTruth(map_image)\n",
    "            \n",
    "#             bg = np.all(map_image == np.array([0, 0, 0]), axis=2)\n",
    "#             bg = bg.reshape(*bg.shape, 1)\n",
    "#             map_image = np.concatenate((bg, np.invert(bg)), axis=2)\n",
    "            \n",
    "            images.append(image)\n",
    "            maps.append(map_image)\n",
    "\n",
    "        yield np.array(images), np.array(maps)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'./vgg/variables/variables'\n",
      "Graph has been built - launching training\n",
      "====== :-) ======\n",
      "Launching Epoch 0\n",
      "Batch 10 - loss of 2.5662927627563477\n",
      "Batch 20 - loss of 2.566408634185791\n",
      "Batch 30 - loss of 2.566331386566162\n",
      "Batch 40 - loss of 2.566340923309326\n",
      "Batch 50 - loss of 2.566460609436035\n",
      "Batch 60 - loss of 2.5665011405944824\n",
      "Batch 70 - loss of 2.566790819168091\n",
      "Batch 80 - loss of 2.5660905838012695\n",
      "Batch 90 - loss of 2.566469430923462\n",
      "Batch 100 - loss of 2.5664682388305664\n",
      "Batch 110 - loss of 2.5663716793060303\n",
      "Batch 120 - loss of 2.5662620067596436\n",
      "Batch 130 - loss of 2.5661227703094482\n",
      "Batch 140 - loss of 2.5667755603790283\n",
      "Batch 150 - loss of 2.566157817840576\n",
      "Batch 160 - loss of 2.5660345554351807\n",
      "Batch 170 - loss of 2.5662550926208496\n",
      "Batch 180 - loss of 2.5660624504089355\n",
      "Batch 190 - loss of 2.5665853023529053\n",
      "Batch 200 - loss of 2.5663137435913086\n",
      "Batch 210 - loss of 2.566566228866577\n",
      "Batch 220 - loss of 2.566211462020874\n",
      "Batch 230 - loss of 2.565944194793701\n",
      "Batch 240 - loss of 2.5662662982940674\n",
      "Batch 250 - loss of 2.5666556358337402\n",
      "Training for epoch finished -  2.566656\n",
      "Launching Epoch 1\n",
      "Batch 10 - loss of 2.566359758377075\n",
      "Batch 20 - loss of 2.5664353370666504\n",
      "Batch 30 - loss of 2.566263198852539\n",
      "Batch 40 - loss of 2.5664329528808594\n",
      "Batch 50 - loss of 2.566500425338745\n",
      "Batch 60 - loss of 2.5665154457092285\n",
      "Batch 70 - loss of 2.5668179988861084\n",
      "Batch 80 - loss of 2.5660738945007324\n",
      "Batch 90 - loss of 2.566474199295044\n",
      "Batch 100 - loss of 2.5664193630218506\n",
      "Batch 110 - loss of 2.566469192504883\n",
      "Batch 120 - loss of 2.566366195678711\n",
      "Batch 130 - loss of 2.566246509552002\n",
      "Batch 140 - loss of 2.566756248474121\n",
      "Batch 150 - loss of 2.5660781860351562\n",
      "Batch 160 - loss of 2.5659775733947754\n",
      "Batch 170 - loss of 2.5663299560546875\n",
      "Batch 180 - loss of 2.5660886764526367\n",
      "Batch 190 - loss of 2.5665929317474365\n",
      "Batch 200 - loss of 2.566316843032837\n",
      "Batch 210 - loss of 2.5665442943573\n",
      "Batch 220 - loss of 2.5662176609039307\n",
      "Batch 230 - loss of 2.565922737121582\n",
      "Batch 240 - loss of 2.566213607788086\n",
      "Batch 250 - loss of 2.5667169094085693\n",
      "Training for epoch finished -  2.566717\n",
      "Launching Epoch 2\n",
      "Batch 10 - loss of 2.56630277633667\n",
      "Batch 20 - loss of 2.5664827823638916\n",
      "Batch 30 - loss of 2.5662827491760254\n",
      "Batch 40 - loss of 2.566399097442627\n",
      "Batch 50 - loss of 2.5664992332458496\n",
      "Batch 60 - loss of 2.5664775371551514\n",
      "Batch 70 - loss of 2.5667622089385986\n",
      "Batch 80 - loss of 2.566114664077759\n",
      "Batch 90 - loss of 2.566404342651367\n",
      "Batch 100 - loss of 2.5664544105529785\n",
      "Batch 110 - loss of 2.566391944885254\n",
      "Batch 120 - loss of 2.5663070678710938\n",
      "Batch 130 - loss of 2.566161870956421\n",
      "Batch 140 - loss of 2.566751003265381\n",
      "Batch 150 - loss of 2.5660972595214844\n",
      "Batch 160 - loss of 2.5660128593444824\n",
      "Batch 170 - loss of 2.5662357807159424\n",
      "Batch 180 - loss of 2.566006898880005\n",
      "Batch 190 - loss of 2.5666182041168213\n",
      "Batch 200 - loss of 2.566293716430664\n",
      "Batch 210 - loss of 2.566453695297241\n",
      "Batch 220 - loss of 2.5662295818328857\n",
      "Batch 230 - loss of 2.5659453868865967\n",
      "Batch 240 - loss of 2.566225528717041\n",
      "Batch 250 - loss of 2.5666861534118652\n",
      "Training for epoch finished -  2.566686\n",
      "Launching Epoch 3\n",
      "Batch 10 - loss of 2.5663442611694336\n",
      "Batch 20 - loss of 2.5663034915924072\n",
      "Batch 30 - loss of 2.5662496089935303\n",
      "Batch 40 - loss of 2.566365957260132\n",
      "Batch 50 - loss of 2.566521167755127\n",
      "Batch 60 - loss of 2.566495180130005\n",
      "Batch 70 - loss of 2.5667853355407715\n",
      "Batch 80 - loss of 2.566084861755371\n",
      "Batch 90 - loss of 2.5664095878601074\n",
      "Batch 100 - loss of 2.5664567947387695\n",
      "Batch 110 - loss of 2.566441535949707\n",
      "Batch 120 - loss of 2.5663259029388428\n",
      "Batch 130 - loss of 2.566152572631836\n",
      "Batch 140 - loss of 2.566664457321167\n",
      "Batch 150 - loss of 2.5660898685455322\n",
      "Batch 160 - loss of 2.566045045852661\n",
      "Batch 170 - loss of 2.5663487911224365\n",
      "Batch 180 - loss of 2.5660574436187744\n",
      "Batch 190 - loss of 2.566549777984619\n",
      "Batch 200 - loss of 2.5662569999694824\n",
      "Batch 210 - loss of 2.566551446914673\n",
      "Batch 220 - loss of 2.5662295818328857\n",
      "Batch 230 - loss of 2.565927505493164\n",
      "Batch 240 - loss of 2.566242218017578\n",
      "Batch 250 - loss of 2.566650152206421\n",
      "Training for epoch finished -  2.566650\n",
      "Launching Epoch 4\n",
      "Batch 10 - loss of 2.5663607120513916\n",
      "Batch 20 - loss of 2.566368341445923\n",
      "Batch 30 - loss of 2.566310167312622\n",
      "Batch 40 - loss of 2.5663726329803467\n",
      "Batch 50 - loss of 2.566493034362793\n",
      "Batch 60 - loss of 2.5665202140808105\n",
      "Batch 70 - loss of 2.5666987895965576\n",
      "Batch 80 - loss of 2.5660390853881836\n",
      "Batch 90 - loss of 2.5664117336273193\n",
      "Batch 100 - loss of 2.5664727687835693\n",
      "Batch 110 - loss of 2.566444158554077\n",
      "Batch 120 - loss of 2.566283941268921\n",
      "Batch 130 - loss of 2.5661675930023193\n",
      "Batch 140 - loss of 2.566706657409668\n",
      "Batch 150 - loss of 2.56615948677063\n",
      "Batch 160 - loss of 2.5660810470581055\n",
      "Batch 170 - loss of 2.566253900527954\n",
      "Batch 180 - loss of 2.5660579204559326\n",
      "Batch 190 - loss of 2.5666253566741943\n",
      "Batch 200 - loss of 2.5663232803344727\n",
      "Batch 210 - loss of 2.566513776779175\n",
      "Batch 220 - loss of 2.5662012100219727\n",
      "Batch 230 - loss of 2.5660555362701416\n",
      "Batch 240 - loss of 2.5662448406219482\n",
      "Batch 250 - loss of 2.566772699356079\n",
      "Training for epoch finished -  2.566773\n",
      "Launching Epoch 5\n",
      "Batch 10 - loss of 2.566314458847046\n",
      "Batch 20 - loss of 2.5663297176361084\n",
      "Batch 30 - loss of 2.5662825107574463\n",
      "Batch 40 - loss of 2.566324472427368\n",
      "Batch 50 - loss of 2.5664987564086914\n",
      "Batch 60 - loss of 2.566492795944214\n",
      "Batch 70 - loss of 2.566755533218384\n",
      "Batch 80 - loss of 2.566084384918213\n",
      "Batch 90 - loss of 2.566415548324585\n",
      "Batch 100 - loss of 2.5664541721343994\n",
      "Batch 110 - loss of 2.5663442611694336\n",
      "Batch 120 - loss of 2.566350221633911\n",
      "Batch 130 - loss of 2.5661981105804443\n",
      "Batch 140 - loss of 2.566739320755005\n",
      "Batch 150 - loss of 2.5660200119018555\n",
      "Batch 160 - loss of 2.566004514694214\n",
      "Batch 170 - loss of 2.566254138946533\n",
      "Batch 180 - loss of 2.5660367012023926\n",
      "Batch 190 - loss of 2.566570997238159\n",
      "Batch 200 - loss of 2.5663485527038574\n",
      "Batch 210 - loss of 2.5664939880371094\n",
      "Batch 220 - loss of 2.5661885738372803\n",
      "Batch 230 - loss of 2.56597900390625\n",
      "Batch 240 - loss of 2.5662338733673096\n",
      "Batch 250 - loss of 2.566657066345215\n",
      "Training for epoch finished -  2.566657\n",
      "Launching Epoch 6\n",
      "Batch 10 - loss of 2.566333293914795\n",
      "Batch 20 - loss of 2.5663487911224365\n",
      "Batch 30 - loss of 2.5663352012634277\n",
      "Batch 40 - loss of 2.5663740634918213\n",
      "Batch 50 - loss of 2.566500425338745\n",
      "Batch 60 - loss of 2.5665128231048584\n",
      "Batch 70 - loss of 2.5668063163757324\n",
      "Batch 80 - loss of 2.5660181045532227\n",
      "Batch 90 - loss of 2.566373586654663\n",
      "Batch 100 - loss of 2.5664594173431396\n",
      "Batch 110 - loss of 2.5663766860961914\n",
      "Batch 120 - loss of 2.566274404525757\n",
      "Batch 130 - loss of 2.5661089420318604\n",
      "Batch 140 - loss of 2.5667428970336914\n",
      "Batch 150 - loss of 2.566147804260254\n",
      "Batch 160 - loss of 2.565997362136841\n",
      "Batch 170 - loss of 2.5662240982055664\n",
      "Batch 180 - loss of 2.566054582595825\n",
      "Batch 190 - loss of 2.5666184425354004\n",
      "Batch 200 - loss of 2.5662899017333984\n",
      "Batch 210 - loss of 2.5664663314819336\n",
      "Batch 220 - loss of 2.566232681274414\n",
      "Batch 230 - loss of 2.565892457962036\n",
      "Batch 240 - loss of 2.5662789344787598\n",
      "Batch 250 - loss of 2.5666325092315674\n",
      "Training for epoch finished -  2.566633\n",
      "Launching Epoch 7\n",
      "Batch 10 - loss of 2.566352605819702\n",
      "Batch 20 - loss of 2.566380023956299\n",
      "Batch 30 - loss of 2.56626558303833\n",
      "Batch 40 - loss of 2.5663225650787354\n",
      "Batch 50 - loss of 2.566474437713623\n",
      "Batch 60 - loss of 2.5665745735168457\n",
      "Batch 70 - loss of 2.56680965423584\n",
      "Batch 80 - loss of 2.5660486221313477\n",
      "Batch 90 - loss of 2.5663695335388184\n",
      "Batch 100 - loss of 2.566493511199951\n",
      "Batch 110 - loss of 2.566342353820801\n",
      "Batch 120 - loss of 2.566312074661255\n",
      "Batch 130 - loss of 2.5661284923553467\n",
      "Batch 140 - loss of 2.566790819168091\n",
      "Batch 150 - loss of 2.566056251525879\n",
      "Batch 160 - loss of 2.5660595893859863\n",
      "Batch 170 - loss of 2.566267251968384\n",
      "Batch 180 - loss of 2.5660908222198486\n",
      "Batch 190 - loss of 2.5666189193725586\n",
      "Batch 200 - loss of 2.5662827491760254\n",
      "Batch 210 - loss of 2.5664710998535156\n",
      "Batch 220 - loss of 2.5661723613739014\n",
      "Batch 230 - loss of 2.565913677215576\n",
      "Batch 240 - loss of 2.566248893737793\n",
      "Batch 250 - loss of 2.566706657409668\n",
      "Training for epoch finished -  2.566707\n",
      "Launching Epoch 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10 - loss of 2.566352128982544\n",
      "Batch 20 - loss of 2.5664217472076416\n",
      "Batch 30 - loss of 2.5663015842437744\n",
      "Batch 40 - loss of 2.5663161277770996\n",
      "Batch 50 - loss of 2.5665361881256104\n",
      "Batch 60 - loss of 2.5664656162261963\n",
      "Batch 70 - loss of 2.5668091773986816\n",
      "Batch 80 - loss of 2.566075563430786\n",
      "Batch 90 - loss of 2.566472291946411\n",
      "Batch 100 - loss of 2.566469430923462\n",
      "Batch 110 - loss of 2.5663952827453613\n",
      "Batch 120 - loss of 2.5663716793060303\n",
      "Batch 130 - loss of 2.5662052631378174\n",
      "Batch 140 - loss of 2.566697359085083\n",
      "Batch 150 - loss of 2.5660977363586426\n",
      "Batch 160 - loss of 2.566046714782715\n",
      "Batch 170 - loss of 2.5661892890930176\n",
      "Batch 180 - loss of 2.5660274028778076\n",
      "Batch 190 - loss of 2.566521644592285\n",
      "Batch 200 - loss of 2.5662550926208496\n",
      "Batch 210 - loss of 2.5664868354797363\n",
      "Batch 220 - loss of 2.5661964416503906\n",
      "Batch 230 - loss of 2.566051483154297\n",
      "Batch 240 - loss of 2.5662474632263184\n",
      "Batch 250 - loss of 2.5666730403900146\n",
      "Training for epoch finished -  2.566673\n",
      "Launching Epoch 9\n",
      "Batch 10 - loss of 2.56638765335083\n",
      "Batch 20 - loss of 2.566361904144287\n",
      "Batch 30 - loss of 2.566202402114868\n",
      "Batch 40 - loss of 2.5663201808929443\n",
      "Batch 50 - loss of 2.566526174545288\n",
      "Batch 60 - loss of 2.5665364265441895\n",
      "Batch 70 - loss of 2.566877841949463\n",
      "Batch 80 - loss of 2.566075325012207\n",
      "Batch 90 - loss of 2.5664777755737305\n",
      "Batch 100 - loss of 2.566488027572632\n",
      "Batch 110 - loss of 2.5663881301879883\n",
      "Batch 120 - loss of 2.5663392543792725\n",
      "Batch 130 - loss of 2.56618595123291\n",
      "Batch 140 - loss of 2.5667874813079834\n",
      "Batch 150 - loss of 2.5660953521728516\n",
      "Batch 160 - loss of 2.5660159587860107\n",
      "Batch 170 - loss of 2.5662946701049805\n",
      "Batch 180 - loss of 2.5660030841827393\n",
      "Batch 190 - loss of 2.5665907859802246\n",
      "Batch 200 - loss of 2.566263437271118\n",
      "Batch 210 - loss of 2.56653094291687\n",
      "Batch 220 - loss of 2.5662569999694824\n",
      "Batch 230 - loss of 2.5659596920013428\n",
      "Batch 240 - loss of 2.5662453174591064\n",
      "Batch 250 - loss of 2.5666720867156982\n",
      "Training for epoch finished -  2.566672\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    #Placeholders\n",
    "    label = tf.placeholder(tf.int32, (None, None, None, num_classes), name='label')\n",
    "    learning_rate = tf.placeholder(tf.int32, name='learning_rate')\n",
    "    \n",
    "    #Grab layers from pretrained VGG\n",
    "    tf.saved_model.loader.load(sess, [\"vgg16\"], \"./vgg/\")\n",
    "    \n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    #define key layers for us to work with, so we can take pieces of VGG16\n",
    "    #for our own use\n",
    "    input_layer = graph.get_tensor_by_name(\"image_input:0\")\n",
    "    keep_prob = graph.get_tensor_by_name(\"keep_prob:0\") #Dropout settings\n",
    "    \n",
    "    #more layer grabbing\n",
    "    layer3 = graph.get_tensor_by_name(\"layer3_out:0\")\n",
    "    layer4 = graph.get_tensor_by_name(\"layer4_out:0\")\n",
    "    layer7 = graph.get_tensor_by_name(\"layer7_out:0\")\n",
    "    \n",
    "    #Create new output layers\n",
    "    #First, a 1x1 convolutional to maintain spacial data\n",
    "    layer_8_conv = tf.layers.conv2d(layer7, num_classes, 1, padding='same', name='layer_8_conv')\n",
    "    \n",
    "    #transpose by 2 for then ext layer\n",
    "    layer_9_transpose = tf.layers.conv2d_transpose(layer_8_conv, num_classes, 4, strides=2, padding='same', name='layer_9_transpose')\n",
    "    \n",
    "    #Another convolution\n",
    "    layer_10_conv = tf.layers.conv2d(layer_9_transpose, num_classes, 1, padding='same', name='layer_10_conv')\n",
    "    \n",
    "    #Skip layer - so we dont lose too much positional information during conv/transposeds\n",
    "    layer_11_skip = tf.add(layer_9_transpose, layer_10_conv, name='layer_11_skip')\n",
    "    \n",
    "    #transpose again\n",
    "    layer_12_transpose = tf.layers.conv2d_transpose(layer_11_skip, num_classes, 4, strides=2, padding='same', name='layer_12_transpose')\n",
    "    \n",
    "    #and convolve...\n",
    "    layer_13_conv = tf.layers.conv2d(layer_12_transpose, num_classes, 1, padding='same', name='layer_13_conv')\n",
    "    \n",
    "    #skip again\n",
    "    layer_14_skip = tf.add(layer_12_transpose, layer_13_conv, name='layer_14_skip')\n",
    "    \n",
    "    #Transpose\n",
    "    output_layer = tf.layers.conv2d_transpose(layer_14_skip, num_classes, 16, strides=8, padding='same', name='output_layer')\n",
    "    \n",
    "    #layer_15 will be our transposed output!\n",
    "    \n",
    "    #Create the optimzer\n",
    "    logits = tf.reshape(output_layer, (-1, num_classes))\n",
    "    correct_label = tf.reshape(label, (-1, num_classes))\n",
    "    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=correct_label))\n",
    "    optimizer= tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(cross_entropy_loss)\n",
    "    \n",
    "    \n",
    "    #and now, training!\n",
    "    epochs = 10\n",
    "    batch_size = 4\n",
    "    keep_probability = 0.9\n",
    "    learning_rate_alpha = 0.001\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print(\"Graph has been built - launching training\")\n",
    "    print(\"====== :-) ======\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Launching Epoch {}\".format(epoch))\n",
    "        loss_log = []\n",
    "        batch_count = 0\n",
    "        \n",
    "        #get the images\n",
    "        for image, truth in get_training_data(batch_size):\n",
    "            batch_count += 1\n",
    "            _, loss = sess.run(\n",
    "                    [train_op, cross_entropy_loss],\n",
    "                    feed_dict = {\n",
    "                        input_layer: image,\n",
    "                        label: truth,\n",
    "                        keep_prob: keep_probability,\n",
    "                        learning_rate: learning_rate_alpha\n",
    "                    }\n",
    "                )\n",
    "            loss_log.append('{:3f}'.format(loss))\n",
    "            if(batch_count % 10 == 0):\n",
    "                print(\"Batch {} - loss of {}\".format(batch_count, loss))\n",
    "        print(\"Training for epoch finished - \", loss_log[-1])\n",
    "    print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
